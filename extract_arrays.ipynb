{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "This notebook produced the numpy arrays required for ml_test.ipynb from 20 second labeled pcaps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on en5 !\n",
      "WARNING: No IPv4 address found on ap1 !\n",
      "WARNING: more No IPv4 address found on awdl0 !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from scapy.all import *\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEFRAME = 20          # Number of seconds per captured frame\n",
    "\n",
    "PATH = \"pcaps/big_capture\"           # Where the clips are saved\n",
    "NAME = \"100_plus_additional_large\"\n",
    "\n",
    "MIN_PACKETS = 20\n",
    "\n",
    "CLIENTS = [\n",
    "    \"192.168.254.0\",\n",
    "    \"192.168.254.1\",\n",
    "    \"192.168.254.2\"\n",
    "]\n",
    "                          # List of Client IP addresses used in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(PATH)\n",
    "clips = [os.path.join(PATH, clip) for clip in dir_list if clip[-5:] == \".pcap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_clips(clip):\n",
    "\n",
    "    matrix = np.zeros([TIMEFRAME * 10, 150, 2])\n",
    "    start_time = clip[0].time\n",
    "    for pkt in clip:\n",
    "        if IP in pkt:\n",
    "            length = (lambda x: x if x <= 1500 else 1500)(pkt[IP].len) # Packets over 1500 are rounded down to 1500\n",
    "            dir = (lambda x: 0 if x[IP].src in CLIENTS else 1)(pkt)\n",
    "            time_round = round(pkt.time - start_time, 1) \n",
    "            matrix[int(time_round * 10)-1][int(length / 10)-1][dir] += 1\n",
    "    return np.array(matrix)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "labels_list =[]\n",
    "\n",
    "for idx, file in enumerate(clips):\n",
    "    clip = rdpcap(file)\n",
    "    if len(clip) > MIN_PACKETS:\n",
    "        features_list.append(extract_features_from_clips(clip))\n",
    "        label = clips[idx][len(PATH)+1:].split(\"-\")[0]\n",
    "        # label = re.split(\"\\d\", label)[0]   # Uncomment for use with ICSX dataset\n",
    "        # label = re.split(\"_[AB]\", label)[0]    # Uncomment for use with ICSX dataset\n",
    "        label = label.split(\"-\")[0]\n",
    "        labels_list.append(label)\n",
    "    del(clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape (18937, 200, 150, 2)\n",
      "labels shape (18937,)\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features_list)\n",
    "labels = np.array(labels_list)\n",
    "\n",
    "print(f\"features shape {features.shape}\\nlabels shape {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0101.co.jp', '2'],\n",
       "       ['0123movie.net', '1'],\n",
       "       ['0123movies.com', '3'],\n",
       "       ...,\n",
       "       ['zzvips.com', '3'],\n",
       "       ['zzzfun.com', '2'],\n",
       "       ['zzzmh.cn', '2']], dtype='<U32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "counts = np.asarray((unique, counts)).T\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save = input(\"Do you want to save? y/n\") == \"y\"\n",
    "save = True\n",
    "\n",
    "if save:\n",
    "    date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "    current_datetime = dt.now()\n",
    "    current_datetime_string = dt.strftime(current_datetime, date_time_format)\n",
    "\n",
    "    with open(f\"data/my_{TIMEFRAME}_sec_features-{NAME}-{current_datetime_string}.npy\", \"wb\") as f:\n",
    "        np.save(f, features)\n",
    "\n",
    "    with open(f\"data/my_{TIMEFRAME}_sec_labels-{NAME}-{current_datetime_string}.npy\", \"wb\") as f:\n",
    "        np.save(f, labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86bc5e1ae678ca00618f5fd2590b9329e90818a147362b03ba7b4466c4d1d957"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('UNB_Datasets-qeLdalLc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
